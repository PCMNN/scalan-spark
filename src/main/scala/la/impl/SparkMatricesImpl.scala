package la
package impl

import scala.annotation.unchecked.uncheckedVariance
import scalan.OverloadId
import scalan.common.OverloadHack.{Overloaded1, Overloaded2}
import scala.reflect._
import scala.reflect.runtime.universe._
import scalan.common.Default
import scalan.spark._

// Abs -----------------------------------
trait SparkMatricesAbs extends SparkMatrices with SparkDsl {
  self: SparkLADsl =>

  // single proxy for each type family
  implicit def proxySparkAbstractMatrix[A](p: Rep[SparkAbstractMatrix[A]]): SparkAbstractMatrix[A] = {
    proxyOps[SparkAbstractMatrix[A]](p)(classTag[SparkAbstractMatrix[A]])
  }

  // familyElem
  class SparkAbstractMatrixElem[A, To <: SparkAbstractMatrix[A]](implicit override val elem: Elem[A])
    extends AbstractMatrixElem[A, To] {
    override def isEntityType = true
    override def tag = {
      implicit val tagA = elem.tag
      weakTypeTag[SparkAbstractMatrix[A]].asInstanceOf[WeakTypeTag[To]]
    }
    override def convert(x: Rep[Reifiable[_]]) = {
      val conv = fun {x: Rep[SparkAbstractMatrix[A]] =>  convertSparkAbstractMatrix(x) }
      tryConvert(element[SparkAbstractMatrix[A]], this, x, conv)
    }

    def convertSparkAbstractMatrix(x : Rep[SparkAbstractMatrix[A]]): Rep[To] = {
      assert(x.selfType1 match { case _: SparkAbstractMatrixElem[_,_] => true case _ => false })
      x.asRep[To]
    }
    override def getDefaultRep: Rep[To] = ???
  }

  implicit def sparkAbstractMatrixElement[A](implicit elem: Elem[A]): Elem[SparkAbstractMatrix[A]] =
    new SparkAbstractMatrixElem[A, SparkAbstractMatrix[A]] {
    }

  trait SparkAbstractMatrixCompanionElem extends CompanionElem[SparkAbstractMatrixCompanionAbs]
  implicit lazy val SparkAbstractMatrixCompanionElem: SparkAbstractMatrixCompanionElem = new SparkAbstractMatrixCompanionElem {
    lazy val tag = weakTypeTag[SparkAbstractMatrixCompanionAbs]
    protected def getDefaultRep = SparkAbstractMatrix
  }

  abstract class SparkAbstractMatrixCompanionAbs extends CompanionBase[SparkAbstractMatrixCompanionAbs] with SparkAbstractMatrixCompanion {
    override def toString = "SparkAbstractMatrix"
  }
  def SparkAbstractMatrix: Rep[SparkAbstractMatrixCompanionAbs]
  implicit def proxySparkAbstractMatrixCompanion(p: Rep[SparkAbstractMatrixCompanion]): SparkAbstractMatrixCompanion = {
    proxyOps[SparkAbstractMatrixCompanion](p)
  }

  // elem for concrete class
  class SparkSparseMatrixElem[T](val iso: Iso[SparkSparseMatrixData[T], SparkSparseMatrix[T]])(implicit elem: Elem[T])
    extends SparkAbstractMatrixElem[T, SparkSparseMatrix[T]]
    with ConcreteElem[SparkSparseMatrixData[T], SparkSparseMatrix[T]] {
    override def convertSparkAbstractMatrix(x: Rep[SparkAbstractMatrix[T]]) = // Converter is not generated by meta
!!!("Cannot convert from SparkAbstractMatrix to SparkSparseMatrix: missing fields List(rddIdxs, rddVals, numColumns)")
    override def getDefaultRep = super[ConcreteElem].getDefaultRep
    override lazy val tag = super[ConcreteElem].tag
  }

  // state representation type
  type SparkSparseMatrixData[T] = (RDDCollection[Array[Int]], (RDDCollection[Array[T]], Int))

  // 3) Iso for concrete class
  class SparkSparseMatrixIso[T](implicit elem: Elem[T])
    extends Iso[SparkSparseMatrixData[T], SparkSparseMatrix[T]]()(pairElement(implicitly[Elem[RDDCollection[Array[Int]]]], pairElement(implicitly[Elem[RDDCollection[Array[T]]]], implicitly[Elem[Int]]))) {
    override def from(p: Rep[SparkSparseMatrix[T]]) =
      (p.rddIdxs, p.rddVals, p.numColumns)
    override def to(p: Rep[(RDDCollection[Array[Int]], (RDDCollection[Array[T]], Int))]) = {
      val Pair(rddIdxs, Pair(rddVals, numColumns)) = p
      SparkSparseMatrix(rddIdxs, rddVals, numColumns)
    }
    lazy val tag = {
      implicit val tagT = elem.tag
      weakTypeTag[SparkSparseMatrix[T]]
    }
    lazy val defaultRepTo = Default.defaultVal[Rep[SparkSparseMatrix[T]]](SparkSparseMatrix(element[RDDCollection[Array[Int]]].defaultRepValue, element[RDDCollection[Array[T]]].defaultRepValue, 0))
    lazy val eTo = new SparkSparseMatrixElem[T](this)
  }
  // 4) constructor and deconstructor
  abstract class SparkSparseMatrixCompanionAbs extends CompanionBase[SparkSparseMatrixCompanionAbs] with SparkSparseMatrixCompanion {
    override def toString = "SparkSparseMatrix"
    def apply[T](p: Rep[SparkSparseMatrixData[T]])(implicit elem: Elem[T]): Rep[SparkSparseMatrix[T]] =
      isoSparkSparseMatrix(elem).to(p)
    def apply[T](rddIdxs: Rep[RDDCollection[Array[Int]]], rddVals: Rep[RDDCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkSparseMatrix[T]] =
      mkSparkSparseMatrix(rddIdxs, rddVals, numColumns)
  }
  object SparkSparseMatrixMatcher {
    def unapply[T](p: Rep[SparkAbstractMatrix[T]]) = unmkSparkSparseMatrix(p)
  }
  def SparkSparseMatrix: Rep[SparkSparseMatrixCompanionAbs]
  implicit def proxySparkSparseMatrixCompanion(p: Rep[SparkSparseMatrixCompanionAbs]): SparkSparseMatrixCompanionAbs = {
    proxyOps[SparkSparseMatrixCompanionAbs](p)
  }

  class SparkSparseMatrixCompanionElem extends CompanionElem[SparkSparseMatrixCompanionAbs] {
    lazy val tag = weakTypeTag[SparkSparseMatrixCompanionAbs]
    protected def getDefaultRep = SparkSparseMatrix
  }
  implicit lazy val SparkSparseMatrixCompanionElem: SparkSparseMatrixCompanionElem = new SparkSparseMatrixCompanionElem

  implicit def proxySparkSparseMatrix[T](p: Rep[SparkSparseMatrix[T]]): SparkSparseMatrix[T] =
    proxyOps[SparkSparseMatrix[T]](p)

  implicit class ExtendedSparkSparseMatrix[T](p: Rep[SparkSparseMatrix[T]])(implicit elem: Elem[T]) {
    def toData: Rep[SparkSparseMatrixData[T]] = isoSparkSparseMatrix(elem).from(p)
  }

  // 5) implicit resolution of Iso
  implicit def isoSparkSparseMatrix[T](implicit elem: Elem[T]): Iso[SparkSparseMatrixData[T], SparkSparseMatrix[T]] =
    new SparkSparseMatrixIso[T]

  // 6) smart constructor and deconstructor
  def mkSparkSparseMatrix[T](rddIdxs: Rep[RDDCollection[Array[Int]]], rddVals: Rep[RDDCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkSparseMatrix[T]]
  def unmkSparkSparseMatrix[T](p: Rep[SparkAbstractMatrix[T]]): Option[(Rep[RDDCollection[Array[Int]]], Rep[RDDCollection[Array[T]]], Rep[Int])]

  // elem for concrete class
  class SparkSparseIndexedMatrixElem[T](val iso: Iso[SparkSparseIndexedMatrixData[T], SparkSparseIndexedMatrix[T]])(implicit elem: Elem[T])
    extends SparkAbstractMatrixElem[T, SparkSparseIndexedMatrix[T]]
    with ConcreteElem[SparkSparseIndexedMatrixData[T], SparkSparseIndexedMatrix[T]] {
    override def convertSparkAbstractMatrix(x: Rep[SparkAbstractMatrix[T]]) = // Converter is not generated by meta
!!!("Cannot convert from SparkAbstractMatrix to SparkSparseIndexedMatrix: missing fields List(rddIdxs, rddVals, numColumns)")
    override def getDefaultRep = super[ConcreteElem].getDefaultRep
    override lazy val tag = super[ConcreteElem].tag
  }

  // state representation type
  type SparkSparseIndexedMatrixData[T] = (RDDIndexedCollection[Array[Int]], (RDDIndexedCollection[Array[T]], Int))

  // 3) Iso for concrete class
  class SparkSparseIndexedMatrixIso[T](implicit elem: Elem[T])
    extends Iso[SparkSparseIndexedMatrixData[T], SparkSparseIndexedMatrix[T]]()(pairElement(implicitly[Elem[RDDIndexedCollection[Array[Int]]]], pairElement(implicitly[Elem[RDDIndexedCollection[Array[T]]]], implicitly[Elem[Int]]))) {
    override def from(p: Rep[SparkSparseIndexedMatrix[T]]) =
      (p.rddIdxs, p.rddVals, p.numColumns)
    override def to(p: Rep[(RDDIndexedCollection[Array[Int]], (RDDIndexedCollection[Array[T]], Int))]) = {
      val Pair(rddIdxs, Pair(rddVals, numColumns)) = p
      SparkSparseIndexedMatrix(rddIdxs, rddVals, numColumns)
    }
    lazy val tag = {
      implicit val tagT = elem.tag
      weakTypeTag[SparkSparseIndexedMatrix[T]]
    }
    lazy val defaultRepTo = Default.defaultVal[Rep[SparkSparseIndexedMatrix[T]]](SparkSparseIndexedMatrix(element[RDDIndexedCollection[Array[Int]]].defaultRepValue, element[RDDIndexedCollection[Array[T]]].defaultRepValue, 0))
    lazy val eTo = new SparkSparseIndexedMatrixElem[T](this)
  }
  // 4) constructor and deconstructor
  abstract class SparkSparseIndexedMatrixCompanionAbs extends CompanionBase[SparkSparseIndexedMatrixCompanionAbs] with SparkSparseIndexedMatrixCompanion {
    override def toString = "SparkSparseIndexedMatrix"
    def apply[T](p: Rep[SparkSparseIndexedMatrixData[T]])(implicit elem: Elem[T]): Rep[SparkSparseIndexedMatrix[T]] =
      isoSparkSparseIndexedMatrix(elem).to(p)
    def apply[T](rddIdxs: Rep[RDDIndexedCollection[Array[Int]]], rddVals: Rep[RDDIndexedCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkSparseIndexedMatrix[T]] =
      mkSparkSparseIndexedMatrix(rddIdxs, rddVals, numColumns)
  }
  object SparkSparseIndexedMatrixMatcher {
    def unapply[T](p: Rep[SparkAbstractMatrix[T]]) = unmkSparkSparseIndexedMatrix(p)
  }
  def SparkSparseIndexedMatrix: Rep[SparkSparseIndexedMatrixCompanionAbs]
  implicit def proxySparkSparseIndexedMatrixCompanion(p: Rep[SparkSparseIndexedMatrixCompanionAbs]): SparkSparseIndexedMatrixCompanionAbs = {
    proxyOps[SparkSparseIndexedMatrixCompanionAbs](p)
  }

  class SparkSparseIndexedMatrixCompanionElem extends CompanionElem[SparkSparseIndexedMatrixCompanionAbs] {
    lazy val tag = weakTypeTag[SparkSparseIndexedMatrixCompanionAbs]
    protected def getDefaultRep = SparkSparseIndexedMatrix
  }
  implicit lazy val SparkSparseIndexedMatrixCompanionElem: SparkSparseIndexedMatrixCompanionElem = new SparkSparseIndexedMatrixCompanionElem

  implicit def proxySparkSparseIndexedMatrix[T](p: Rep[SparkSparseIndexedMatrix[T]]): SparkSparseIndexedMatrix[T] =
    proxyOps[SparkSparseIndexedMatrix[T]](p)

  implicit class ExtendedSparkSparseIndexedMatrix[T](p: Rep[SparkSparseIndexedMatrix[T]])(implicit elem: Elem[T]) {
    def toData: Rep[SparkSparseIndexedMatrixData[T]] = isoSparkSparseIndexedMatrix(elem).from(p)
  }

  // 5) implicit resolution of Iso
  implicit def isoSparkSparseIndexedMatrix[T](implicit elem: Elem[T]): Iso[SparkSparseIndexedMatrixData[T], SparkSparseIndexedMatrix[T]] =
    new SparkSparseIndexedMatrixIso[T]

  // 6) smart constructor and deconstructor
  def mkSparkSparseIndexedMatrix[T](rddIdxs: Rep[RDDIndexedCollection[Array[Int]]], rddVals: Rep[RDDIndexedCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkSparseIndexedMatrix[T]]
  def unmkSparkSparseIndexedMatrix[T](p: Rep[SparkAbstractMatrix[T]]): Option[(Rep[RDDIndexedCollection[Array[Int]]], Rep[RDDIndexedCollection[Array[T]]], Rep[Int])]

  // elem for concrete class
  class SparkDenseMatrixElem[T](val iso: Iso[SparkDenseMatrixData[T], SparkDenseMatrix[T]])(implicit elem: Elem[T])
    extends SparkAbstractMatrixElem[T, SparkDenseMatrix[T]]
    with ConcreteElem[SparkDenseMatrixData[T], SparkDenseMatrix[T]] {
    override def convertSparkAbstractMatrix(x: Rep[SparkAbstractMatrix[T]]) = // Converter is not generated by meta
!!!("Cannot convert from SparkAbstractMatrix to SparkDenseMatrix: missing fields List(rddVals, numColumns)")
    override def getDefaultRep = super[ConcreteElem].getDefaultRep
    override lazy val tag = super[ConcreteElem].tag
  }

  // state representation type
  type SparkDenseMatrixData[T] = (RDDCollection[Array[T]], Int)

  // 3) Iso for concrete class
  class SparkDenseMatrixIso[T](implicit elem: Elem[T])
    extends Iso[SparkDenseMatrixData[T], SparkDenseMatrix[T]]()(pairElement(implicitly[Elem[RDDCollection[Array[T]]]], implicitly[Elem[Int]])) {
    override def from(p: Rep[SparkDenseMatrix[T]]) =
      (p.rddVals, p.numColumns)
    override def to(p: Rep[(RDDCollection[Array[T]], Int)]) = {
      val Pair(rddVals, numColumns) = p
      SparkDenseMatrix(rddVals, numColumns)
    }
    lazy val tag = {
      implicit val tagT = elem.tag
      weakTypeTag[SparkDenseMatrix[T]]
    }
    lazy val defaultRepTo = Default.defaultVal[Rep[SparkDenseMatrix[T]]](SparkDenseMatrix(element[RDDCollection[Array[T]]].defaultRepValue, 0))
    lazy val eTo = new SparkDenseMatrixElem[T](this)
  }
  // 4) constructor and deconstructor
  abstract class SparkDenseMatrixCompanionAbs extends CompanionBase[SparkDenseMatrixCompanionAbs] with SparkDenseMatrixCompanion {
    override def toString = "SparkDenseMatrix"
    def apply[T](p: Rep[SparkDenseMatrixData[T]])(implicit elem: Elem[T]): Rep[SparkDenseMatrix[T]] =
      isoSparkDenseMatrix(elem).to(p)
    def apply[T](rddVals: Rep[RDDCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkDenseMatrix[T]] =
      mkSparkDenseMatrix(rddVals, numColumns)
  }
  object SparkDenseMatrixMatcher {
    def unapply[T](p: Rep[SparkAbstractMatrix[T]]) = unmkSparkDenseMatrix(p)
  }
  def SparkDenseMatrix: Rep[SparkDenseMatrixCompanionAbs]
  implicit def proxySparkDenseMatrixCompanion(p: Rep[SparkDenseMatrixCompanionAbs]): SparkDenseMatrixCompanionAbs = {
    proxyOps[SparkDenseMatrixCompanionAbs](p)
  }

  class SparkDenseMatrixCompanionElem extends CompanionElem[SparkDenseMatrixCompanionAbs] {
    lazy val tag = weakTypeTag[SparkDenseMatrixCompanionAbs]
    protected def getDefaultRep = SparkDenseMatrix
  }
  implicit lazy val SparkDenseMatrixCompanionElem: SparkDenseMatrixCompanionElem = new SparkDenseMatrixCompanionElem

  implicit def proxySparkDenseMatrix[T](p: Rep[SparkDenseMatrix[T]]): SparkDenseMatrix[T] =
    proxyOps[SparkDenseMatrix[T]](p)

  implicit class ExtendedSparkDenseMatrix[T](p: Rep[SparkDenseMatrix[T]])(implicit elem: Elem[T]) {
    def toData: Rep[SparkDenseMatrixData[T]] = isoSparkDenseMatrix(elem).from(p)
  }

  // 5) implicit resolution of Iso
  implicit def isoSparkDenseMatrix[T](implicit elem: Elem[T]): Iso[SparkDenseMatrixData[T], SparkDenseMatrix[T]] =
    new SparkDenseMatrixIso[T]

  // 6) smart constructor and deconstructor
  def mkSparkDenseMatrix[T](rddVals: Rep[RDDCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkDenseMatrix[T]]
  def unmkSparkDenseMatrix[T](p: Rep[SparkAbstractMatrix[T]]): Option[(Rep[RDDCollection[Array[T]]], Rep[Int])]

  // elem for concrete class
  class SparkDenseIndexedMatrixElem[T](val iso: Iso[SparkDenseIndexedMatrixData[T], SparkDenseIndexedMatrix[T]])(implicit elem: Elem[T])
    extends SparkAbstractMatrixElem[T, SparkDenseIndexedMatrix[T]]
    with ConcreteElem[SparkDenseIndexedMatrixData[T], SparkDenseIndexedMatrix[T]] {
    override def convertSparkAbstractMatrix(x: Rep[SparkAbstractMatrix[T]]) = // Converter is not generated by meta
!!!("Cannot convert from SparkAbstractMatrix to SparkDenseIndexedMatrix: missing fields List(rddVals, numColumns)")
    override def getDefaultRep = super[ConcreteElem].getDefaultRep
    override lazy val tag = super[ConcreteElem].tag
  }

  // state representation type
  type SparkDenseIndexedMatrixData[T] = (RDDIndexedCollection[Array[T]], Int)

  // 3) Iso for concrete class
  class SparkDenseIndexedMatrixIso[T](implicit elem: Elem[T])
    extends Iso[SparkDenseIndexedMatrixData[T], SparkDenseIndexedMatrix[T]]()(pairElement(implicitly[Elem[RDDIndexedCollection[Array[T]]]], implicitly[Elem[Int]])) {
    override def from(p: Rep[SparkDenseIndexedMatrix[T]]) =
      (p.rddVals, p.numColumns)
    override def to(p: Rep[(RDDIndexedCollection[Array[T]], Int)]) = {
      val Pair(rddVals, numColumns) = p
      SparkDenseIndexedMatrix(rddVals, numColumns)
    }
    lazy val tag = {
      implicit val tagT = elem.tag
      weakTypeTag[SparkDenseIndexedMatrix[T]]
    }
    lazy val defaultRepTo = Default.defaultVal[Rep[SparkDenseIndexedMatrix[T]]](SparkDenseIndexedMatrix(element[RDDIndexedCollection[Array[T]]].defaultRepValue, 0))
    lazy val eTo = new SparkDenseIndexedMatrixElem[T](this)
  }
  // 4) constructor and deconstructor
  abstract class SparkDenseIndexedMatrixCompanionAbs extends CompanionBase[SparkDenseIndexedMatrixCompanionAbs] with SparkDenseIndexedMatrixCompanion {
    override def toString = "SparkDenseIndexedMatrix"
    def apply[T](p: Rep[SparkDenseIndexedMatrixData[T]])(implicit elem: Elem[T]): Rep[SparkDenseIndexedMatrix[T]] =
      isoSparkDenseIndexedMatrix(elem).to(p)
    def apply[T](rddVals: Rep[RDDIndexedCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkDenseIndexedMatrix[T]] =
      mkSparkDenseIndexedMatrix(rddVals, numColumns)
  }
  object SparkDenseIndexedMatrixMatcher {
    def unapply[T](p: Rep[SparkAbstractMatrix[T]]) = unmkSparkDenseIndexedMatrix(p)
  }
  def SparkDenseIndexedMatrix: Rep[SparkDenseIndexedMatrixCompanionAbs]
  implicit def proxySparkDenseIndexedMatrixCompanion(p: Rep[SparkDenseIndexedMatrixCompanionAbs]): SparkDenseIndexedMatrixCompanionAbs = {
    proxyOps[SparkDenseIndexedMatrixCompanionAbs](p)
  }

  class SparkDenseIndexedMatrixCompanionElem extends CompanionElem[SparkDenseIndexedMatrixCompanionAbs] {
    lazy val tag = weakTypeTag[SparkDenseIndexedMatrixCompanionAbs]
    protected def getDefaultRep = SparkDenseIndexedMatrix
  }
  implicit lazy val SparkDenseIndexedMatrixCompanionElem: SparkDenseIndexedMatrixCompanionElem = new SparkDenseIndexedMatrixCompanionElem

  implicit def proxySparkDenseIndexedMatrix[T](p: Rep[SparkDenseIndexedMatrix[T]]): SparkDenseIndexedMatrix[T] =
    proxyOps[SparkDenseIndexedMatrix[T]](p)

  implicit class ExtendedSparkDenseIndexedMatrix[T](p: Rep[SparkDenseIndexedMatrix[T]])(implicit elem: Elem[T]) {
    def toData: Rep[SparkDenseIndexedMatrixData[T]] = isoSparkDenseIndexedMatrix(elem).from(p)
  }

  // 5) implicit resolution of Iso
  implicit def isoSparkDenseIndexedMatrix[T](implicit elem: Elem[T]): Iso[SparkDenseIndexedMatrixData[T], SparkDenseIndexedMatrix[T]] =
    new SparkDenseIndexedMatrixIso[T]

  // 6) smart constructor and deconstructor
  def mkSparkDenseIndexedMatrix[T](rddVals: Rep[RDDIndexedCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkDenseIndexedMatrix[T]]
  def unmkSparkDenseIndexedMatrix[T](p: Rep[SparkAbstractMatrix[T]]): Option[(Rep[RDDIndexedCollection[Array[T]]], Rep[Int])]
}

// Seq -----------------------------------
trait SparkMatricesSeq extends SparkMatricesDsl with SparkDslSeq {
  self: SparkLADslSeq =>
  lazy val SparkAbstractMatrix: Rep[SparkAbstractMatrixCompanionAbs] = new SparkAbstractMatrixCompanionAbs with UserTypeSeq[SparkAbstractMatrixCompanionAbs] {
    lazy val selfType = element[SparkAbstractMatrixCompanionAbs]
  }

  case class SeqSparkSparseMatrix[T]
      (override val rddIdxs: Rep[RDDCollection[Array[Int]]], override val rddVals: Rep[RDDCollection[Array[T]]], override val numColumns: Rep[Int])
      (implicit elem: Elem[T])
    extends SparkSparseMatrix[T](rddIdxs, rddVals, numColumns)
        with UserTypeSeq[SparkSparseMatrix[T]] {
    lazy val selfType = element[SparkSparseMatrix[T]]
  }
  lazy val SparkSparseMatrix = new SparkSparseMatrixCompanionAbs with UserTypeSeq[SparkSparseMatrixCompanionAbs] {
    lazy val selfType = element[SparkSparseMatrixCompanionAbs]
  }

  def mkSparkSparseMatrix[T]
      (rddIdxs: Rep[RDDCollection[Array[Int]]], rddVals: Rep[RDDCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkSparseMatrix[T]] =
      new SeqSparkSparseMatrix[T](rddIdxs, rddVals, numColumns)
  def unmkSparkSparseMatrix[T](p: Rep[SparkAbstractMatrix[T]]) = p match {
    case p: SparkSparseMatrix[T] @unchecked =>
      Some((p.rddIdxs, p.rddVals, p.numColumns))
    case _ => None
  }

  case class SeqSparkSparseIndexedMatrix[T]
      (override val rddIdxs: Rep[RDDIndexedCollection[Array[Int]]], override val rddVals: Rep[RDDIndexedCollection[Array[T]]], override val numColumns: Rep[Int])
      (implicit elem: Elem[T])
    extends SparkSparseIndexedMatrix[T](rddIdxs, rddVals, numColumns)
        with UserTypeSeq[SparkSparseIndexedMatrix[T]] {
    lazy val selfType = element[SparkSparseIndexedMatrix[T]]
  }
  lazy val SparkSparseIndexedMatrix = new SparkSparseIndexedMatrixCompanionAbs with UserTypeSeq[SparkSparseIndexedMatrixCompanionAbs] {
    lazy val selfType = element[SparkSparseIndexedMatrixCompanionAbs]
  }

  def mkSparkSparseIndexedMatrix[T]
      (rddIdxs: Rep[RDDIndexedCollection[Array[Int]]], rddVals: Rep[RDDIndexedCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkSparseIndexedMatrix[T]] =
      new SeqSparkSparseIndexedMatrix[T](rddIdxs, rddVals, numColumns)
  def unmkSparkSparseIndexedMatrix[T](p: Rep[SparkAbstractMatrix[T]]) = p match {
    case p: SparkSparseIndexedMatrix[T] @unchecked =>
      Some((p.rddIdxs, p.rddVals, p.numColumns))
    case _ => None
  }

  case class SeqSparkDenseMatrix[T]
      (override val rddVals: Rep[RDDCollection[Array[T]]], override val numColumns: Rep[Int])
      (implicit elem: Elem[T])
    extends SparkDenseMatrix[T](rddVals, numColumns)
        with UserTypeSeq[SparkDenseMatrix[T]] {
    lazy val selfType = element[SparkDenseMatrix[T]]
  }
  lazy val SparkDenseMatrix = new SparkDenseMatrixCompanionAbs with UserTypeSeq[SparkDenseMatrixCompanionAbs] {
    lazy val selfType = element[SparkDenseMatrixCompanionAbs]
  }

  def mkSparkDenseMatrix[T]
      (rddVals: Rep[RDDCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkDenseMatrix[T]] =
      new SeqSparkDenseMatrix[T](rddVals, numColumns)
  def unmkSparkDenseMatrix[T](p: Rep[SparkAbstractMatrix[T]]) = p match {
    case p: SparkDenseMatrix[T] @unchecked =>
      Some((p.rddVals, p.numColumns))
    case _ => None
  }

  case class SeqSparkDenseIndexedMatrix[T]
      (override val rddVals: Rep[RDDIndexedCollection[Array[T]]], override val numColumns: Rep[Int])
      (implicit elem: Elem[T])
    extends SparkDenseIndexedMatrix[T](rddVals, numColumns)
        with UserTypeSeq[SparkDenseIndexedMatrix[T]] {
    lazy val selfType = element[SparkDenseIndexedMatrix[T]]
  }
  lazy val SparkDenseIndexedMatrix = new SparkDenseIndexedMatrixCompanionAbs with UserTypeSeq[SparkDenseIndexedMatrixCompanionAbs] {
    lazy val selfType = element[SparkDenseIndexedMatrixCompanionAbs]
  }

  def mkSparkDenseIndexedMatrix[T]
      (rddVals: Rep[RDDIndexedCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkDenseIndexedMatrix[T]] =
      new SeqSparkDenseIndexedMatrix[T](rddVals, numColumns)
  def unmkSparkDenseIndexedMatrix[T](p: Rep[SparkAbstractMatrix[T]]) = p match {
    case p: SparkDenseIndexedMatrix[T] @unchecked =>
      Some((p.rddVals, p.numColumns))
    case _ => None
  }
}

// Exp -----------------------------------
trait SparkMatricesExp extends SparkMatricesDsl with SparkDslExp {
  self: SparkLADslExp =>
  lazy val SparkAbstractMatrix: Rep[SparkAbstractMatrixCompanionAbs] = new SparkAbstractMatrixCompanionAbs with UserTypeDef[SparkAbstractMatrixCompanionAbs] {
    lazy val selfType = element[SparkAbstractMatrixCompanionAbs]
    override def mirror(t: Transformer) = this
  }

  case class ExpSparkSparseMatrix[T]
      (override val rddIdxs: Rep[RDDCollection[Array[Int]]], override val rddVals: Rep[RDDCollection[Array[T]]], override val numColumns: Rep[Int])
      (implicit elem: Elem[T])
    extends SparkSparseMatrix[T](rddIdxs, rddVals, numColumns) with UserTypeDef[SparkSparseMatrix[T]] {
    lazy val selfType = element[SparkSparseMatrix[T]]
    override def mirror(t: Transformer) = ExpSparkSparseMatrix[T](t(rddIdxs), t(rddVals), t(numColumns))
  }

  lazy val SparkSparseMatrix: Rep[SparkSparseMatrixCompanionAbs] = new SparkSparseMatrixCompanionAbs with UserTypeDef[SparkSparseMatrixCompanionAbs] {
    lazy val selfType = element[SparkSparseMatrixCompanionAbs]
    override def mirror(t: Transformer) = this
  }

  object SparkSparseMatrixMethods {
    object numRows {
      def unapply(d: Def[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "numRows" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkSparseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object rddColl {
      def unapply(d: Def[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "rddColl" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkSparseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object sc {
      def unapply(d: Def[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "sc" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkSparseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object rows {
      def unapply(d: Def[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "rows" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkSparseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object rmValues {
      def unapply(d: Def[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "rmValues" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkSparseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object apply_rows {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Coll[Int]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(iRows, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "apply" && { val ann = method.getAnnotation(classOf[scalan.OverloadId]); ann != null && ann.value == "rows" } =>
          Some((receiver, iRows)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Coll[Int]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Coll[Int]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object apply_row {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[Int]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(row, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "apply" && { val ann = method.getAnnotation(classOf[scalan.OverloadId]); ann != null && ann.value == "row" } =>
          Some((receiver, row)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Rep[Int]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[Int]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object apply {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[Int], Rep[Int]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(row, column, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "apply" && method.getAnnotation(classOf[scalan.OverloadId]) == null =>
          Some((receiver, row, column)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Rep[Int], Rep[Int]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[Int], Rep[Int]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object mapBy {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[AbstractVector[T] => AbstractVector[R]]) forSome {type T; type R}] = d match {
        case MethodCall(receiver, method, Seq(f, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "mapBy" =>
          Some((receiver, f)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Rep[AbstractVector[T] => AbstractVector[R]]) forSome {type T; type R}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[AbstractVector[T] => AbstractVector[R]]) forSome {type T; type R}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object columns {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(n, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "columns" =>
          Some((receiver, n)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object transpose {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(n, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "transpose" =>
          Some((receiver, n)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object reduceByRows {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], RepMonoid[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(m, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "reduceByRows" =>
          Some((receiver, m)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], RepMonoid[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], RepMonoid[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object countNonZeroesByColumns {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(n, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "countNonZeroesByColumns" =>
          Some((receiver, n)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object reduceByColumns {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], RepMonoid[T], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(m, n, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "reduceByColumns" =>
          Some((receiver, m, n)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], RepMonoid[T], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], RepMonoid[T], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object * {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Vector[T], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(vector, n, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "$times" && method.getAnnotation(classOf[scalan.OverloadId]) == null =>
          Some((receiver, vector, n)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Vector[T], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Vector[T], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object matrix_* {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Matrix[T], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(matrix, n, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "$times" && { val ann = method.getAnnotation(classOf[scalan.OverloadId]); ann != null && ann.value == "matrix" } =>
          Some((receiver, matrix, n)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Matrix[T], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Matrix[T], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object matrix_+^^ {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(other, n, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "$plus$up$up" =>
          Some((receiver, other, n)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object *^^ {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(other, n, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "$times$up$up" =>
          Some((receiver, other, n)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object average {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Fractional[T], RepMonoid[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(f, m, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "average" =>
          Some((receiver, f, m)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Fractional[T], RepMonoid[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Fractional[T], RepMonoid[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object companion {
      def unapply(d: Def[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "companion" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkSparseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }
  }

  object SparkSparseMatrixCompanionMethods {
  }

  def mkSparkSparseMatrix[T]
    (rddIdxs: Rep[RDDCollection[Array[Int]]], rddVals: Rep[RDDCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkSparseMatrix[T]] =
    new ExpSparkSparseMatrix[T](rddIdxs, rddVals, numColumns)
  def unmkSparkSparseMatrix[T](p: Rep[SparkAbstractMatrix[T]]) = p.elem.asInstanceOf[Elem[_]] match {
    case _: SparkSparseMatrixElem[T] @unchecked =>
      Some((p.asRep[SparkSparseMatrix[T]].rddIdxs, p.asRep[SparkSparseMatrix[T]].rddVals, p.asRep[SparkSparseMatrix[T]].numColumns))
    case _ =>
      None
  }

  case class ExpSparkSparseIndexedMatrix[T]
      (override val rddIdxs: Rep[RDDIndexedCollection[Array[Int]]], override val rddVals: Rep[RDDIndexedCollection[Array[T]]], override val numColumns: Rep[Int])
      (implicit elem: Elem[T])
    extends SparkSparseIndexedMatrix[T](rddIdxs, rddVals, numColumns) with UserTypeDef[SparkSparseIndexedMatrix[T]] {
    lazy val selfType = element[SparkSparseIndexedMatrix[T]]
    override def mirror(t: Transformer) = ExpSparkSparseIndexedMatrix[T](t(rddIdxs), t(rddVals), t(numColumns))
  }

  lazy val SparkSparseIndexedMatrix: Rep[SparkSparseIndexedMatrixCompanionAbs] = new SparkSparseIndexedMatrixCompanionAbs with UserTypeDef[SparkSparseIndexedMatrixCompanionAbs] {
    lazy val selfType = element[SparkSparseIndexedMatrixCompanionAbs]
    override def mirror(t: Transformer) = this
  }

  object SparkSparseIndexedMatrixMethods {
    object numRows {
      def unapply(d: Def[_]): Option[Rep[SparkSparseIndexedMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkSparseIndexedMatrixElem[_]] && method.getName == "numRows" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkSparseIndexedMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkSparseIndexedMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object rddColl {
      def unapply(d: Def[_]): Option[Rep[SparkSparseIndexedMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkSparseIndexedMatrixElem[_]] && method.getName == "rddColl" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkSparseIndexedMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkSparseIndexedMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object sc {
      def unapply(d: Def[_]): Option[Rep[SparkSparseIndexedMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkSparseIndexedMatrixElem[_]] && method.getName == "sc" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkSparseIndexedMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkSparseIndexedMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object rows {
      def unapply(d: Def[_]): Option[Rep[SparkSparseIndexedMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkSparseIndexedMatrixElem[_]] && method.getName == "rows" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkSparseIndexedMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkSparseIndexedMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object rmValues {
      def unapply(d: Def[_]): Option[Rep[SparkSparseIndexedMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkSparseIndexedMatrixElem[_]] && method.getName == "rmValues" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkSparseIndexedMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkSparseIndexedMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object apply_rows {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], Coll[Int]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(iRows, _*), _) if receiver.elem.isInstanceOf[SparkSparseIndexedMatrixElem[_]] && method.getName == "apply" && { val ann = method.getAnnotation(classOf[scalan.OverloadId]); ann != null && ann.value == "rows" } =>
          Some((receiver, iRows)).asInstanceOf[Option[(Rep[SparkSparseIndexedMatrix[T]], Coll[Int]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], Coll[Int]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object apply_row {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], Rep[Int]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(row, _*), _) if receiver.elem.isInstanceOf[SparkSparseIndexedMatrixElem[_]] && method.getName == "apply" && { val ann = method.getAnnotation(classOf[scalan.OverloadId]); ann != null && ann.value == "row" } =>
          Some((receiver, row)).asInstanceOf[Option[(Rep[SparkSparseIndexedMatrix[T]], Rep[Int]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], Rep[Int]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object apply {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], Rep[Int], Rep[Int]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(row, column, _*), _) if receiver.elem.isInstanceOf[SparkSparseIndexedMatrixElem[_]] && method.getName == "apply" && method.getAnnotation(classOf[scalan.OverloadId]) == null =>
          Some((receiver, row, column)).asInstanceOf[Option[(Rep[SparkSparseIndexedMatrix[T]], Rep[Int], Rep[Int]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], Rep[Int], Rep[Int]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object mapBy {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], Rep[AbstractVector[T] => AbstractVector[R]]) forSome {type T; type R}] = d match {
        case MethodCall(receiver, method, Seq(f, _*), _) if receiver.elem.isInstanceOf[SparkSparseIndexedMatrixElem[_]] && method.getName == "mapBy" =>
          Some((receiver, f)).asInstanceOf[Option[(Rep[SparkSparseIndexedMatrix[T]], Rep[AbstractVector[T] => AbstractVector[R]]) forSome {type T; type R}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], Rep[AbstractVector[T] => AbstractVector[R]]) forSome {type T; type R}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object columns {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(n, _*), _) if receiver.elem.isInstanceOf[SparkSparseIndexedMatrixElem[_]] && method.getName == "columns" =>
          Some((receiver, n)).asInstanceOf[Option[(Rep[SparkSparseIndexedMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object transpose {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(n, _*), _) if receiver.elem.isInstanceOf[SparkSparseIndexedMatrixElem[_]] && method.getName == "transpose" =>
          Some((receiver, n)).asInstanceOf[Option[(Rep[SparkSparseIndexedMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object reduceByRows {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], RepMonoid[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(m, _*), _) if receiver.elem.isInstanceOf[SparkSparseIndexedMatrixElem[_]] && method.getName == "reduceByRows" =>
          Some((receiver, m)).asInstanceOf[Option[(Rep[SparkSparseIndexedMatrix[T]], RepMonoid[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], RepMonoid[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object countNonZeroesByColumns {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(n, _*), _) if receiver.elem.isInstanceOf[SparkSparseIndexedMatrixElem[_]] && method.getName == "countNonZeroesByColumns" =>
          Some((receiver, n)).asInstanceOf[Option[(Rep[SparkSparseIndexedMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object reduceByColumns {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], RepMonoid[T], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(m, n, _*), _) if receiver.elem.isInstanceOf[SparkSparseIndexedMatrixElem[_]] && method.getName == "reduceByColumns" =>
          Some((receiver, m, n)).asInstanceOf[Option[(Rep[SparkSparseIndexedMatrix[T]], RepMonoid[T], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], RepMonoid[T], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object * {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], Vector[T], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(vector, n, _*), _) if receiver.elem.isInstanceOf[SparkSparseIndexedMatrixElem[_]] && method.getName == "$times" && method.getAnnotation(classOf[scalan.OverloadId]) == null =>
          Some((receiver, vector, n)).asInstanceOf[Option[(Rep[SparkSparseIndexedMatrix[T]], Vector[T], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], Vector[T], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object matrix_* {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], Matrix[T], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(matrix, n, _*), _) if receiver.elem.isInstanceOf[SparkSparseIndexedMatrixElem[_]] && method.getName == "$times" && { val ann = method.getAnnotation(classOf[scalan.OverloadId]); ann != null && ann.value == "matrix" } =>
          Some((receiver, matrix, n)).asInstanceOf[Option[(Rep[SparkSparseIndexedMatrix[T]], Matrix[T], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], Matrix[T], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object matrix_+^^ {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(other, n, _*), _) if receiver.elem.isInstanceOf[SparkSparseIndexedMatrixElem[_]] && method.getName == "$plus$up$up" =>
          Some((receiver, other, n)).asInstanceOf[Option[(Rep[SparkSparseIndexedMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object *^^ {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(other, n, _*), _) if receiver.elem.isInstanceOf[SparkSparseIndexedMatrixElem[_]] && method.getName == "$times$up$up" =>
          Some((receiver, other, n)).asInstanceOf[Option[(Rep[SparkSparseIndexedMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object average {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], Fractional[T], RepMonoid[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(f, m, _*), _) if receiver.elem.isInstanceOf[SparkSparseIndexedMatrixElem[_]] && method.getName == "average" =>
          Some((receiver, f, m)).asInstanceOf[Option[(Rep[SparkSparseIndexedMatrix[T]], Fractional[T], RepMonoid[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseIndexedMatrix[T]], Fractional[T], RepMonoid[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object companion {
      def unapply(d: Def[_]): Option[Rep[SparkSparseIndexedMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkSparseIndexedMatrixElem[_]] && method.getName == "companion" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkSparseIndexedMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkSparseIndexedMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }
  }

  object SparkSparseIndexedMatrixCompanionMethods {
  }

  def mkSparkSparseIndexedMatrix[T]
    (rddIdxs: Rep[RDDIndexedCollection[Array[Int]]], rddVals: Rep[RDDIndexedCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkSparseIndexedMatrix[T]] =
    new ExpSparkSparseIndexedMatrix[T](rddIdxs, rddVals, numColumns)
  def unmkSparkSparseIndexedMatrix[T](p: Rep[SparkAbstractMatrix[T]]) = p.elem.asInstanceOf[Elem[_]] match {
    case _: SparkSparseIndexedMatrixElem[T] @unchecked =>
      Some((p.asRep[SparkSparseIndexedMatrix[T]].rddIdxs, p.asRep[SparkSparseIndexedMatrix[T]].rddVals, p.asRep[SparkSparseIndexedMatrix[T]].numColumns))
    case _ =>
      None
  }

  case class ExpSparkDenseMatrix[T]
      (override val rddVals: Rep[RDDCollection[Array[T]]], override val numColumns: Rep[Int])
      (implicit elem: Elem[T])
    extends SparkDenseMatrix[T](rddVals, numColumns) with UserTypeDef[SparkDenseMatrix[T]] {
    lazy val selfType = element[SparkDenseMatrix[T]]
    override def mirror(t: Transformer) = ExpSparkDenseMatrix[T](t(rddVals), t(numColumns))
  }

  lazy val SparkDenseMatrix: Rep[SparkDenseMatrixCompanionAbs] = new SparkDenseMatrixCompanionAbs with UserTypeDef[SparkDenseMatrixCompanionAbs] {
    lazy val selfType = element[SparkDenseMatrixCompanionAbs]
    override def mirror(t: Transformer) = this
  }

  object SparkDenseMatrixMethods {
    object numRows {
      def unapply(d: Def[_]): Option[Rep[SparkDenseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "numRows" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkDenseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkDenseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object sc {
      def unapply(d: Def[_]): Option[Rep[SparkDenseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "sc" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkDenseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkDenseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object rows {
      def unapply(d: Def[_]): Option[Rep[SparkDenseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "rows" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkDenseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkDenseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object rmValues {
      def unapply(d: Def[_]): Option[Rep[SparkDenseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "rmValues" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkDenseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkDenseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object apply_rows {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], Coll[Int]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(iRows, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "apply" && { val ann = method.getAnnotation(classOf[scalan.OverloadId]); ann != null && ann.value == "rows" } =>
          Some((receiver, iRows)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], Coll[Int]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], Coll[Int]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object apply_row {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], Rep[Int]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(row, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "apply" && { val ann = method.getAnnotation(classOf[scalan.OverloadId]); ann != null && ann.value == "row" } =>
          Some((receiver, row)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], Rep[Int]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], Rep[Int]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object apply {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], Rep[Int], Rep[Int]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(row, column, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "apply" && method.getAnnotation(classOf[scalan.OverloadId]) == null =>
          Some((receiver, row, column)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], Rep[Int], Rep[Int]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], Rep[Int], Rep[Int]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object mapBy {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], Rep[AbstractVector[T] => AbstractVector[R]]) forSome {type T; type R}] = d match {
        case MethodCall(receiver, method, Seq(f, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "mapBy" =>
          Some((receiver, f)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], Rep[AbstractVector[T] => AbstractVector[R]]) forSome {type T; type R}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], Rep[AbstractVector[T] => AbstractVector[R]]) forSome {type T; type R}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object columns {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(n, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "columns" =>
          Some((receiver, n)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object transpose {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(n, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "transpose" =>
          Some((receiver, n)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object reduceByRows {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], RepMonoid[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(m, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "reduceByRows" =>
          Some((receiver, m)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], RepMonoid[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], RepMonoid[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object countNonZeroesByColumns {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(n, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "countNonZeroesByColumns" =>
          Some((receiver, n)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object reduceByColumns {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], RepMonoid[T], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(m, n, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "reduceByColumns" =>
          Some((receiver, m, n)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], RepMonoid[T], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], RepMonoid[T], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object * {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], Vector[T], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(vector, n, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "$times" && method.getAnnotation(classOf[scalan.OverloadId]) == null =>
          Some((receiver, vector, n)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], Vector[T], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], Vector[T], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object matrix_* {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], Matrix[T], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(matrix, n, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "$times" && { val ann = method.getAnnotation(classOf[scalan.OverloadId]); ann != null && ann.value == "matrix" } =>
          Some((receiver, matrix, n)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], Matrix[T], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], Matrix[T], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object matrix_+^^ {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(other, n, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "$plus$up$up" =>
          Some((receiver, other, n)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object *^^ {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(other, n, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "$times$up$up" =>
          Some((receiver, other, n)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object average {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], Fractional[T], RepMonoid[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(f, m, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "average" =>
          Some((receiver, f, m)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], Fractional[T], RepMonoid[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], Fractional[T], RepMonoid[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object companion {
      def unapply(d: Def[_]): Option[Rep[SparkDenseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "companion" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkDenseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkDenseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }
  }

  object SparkDenseMatrixCompanionMethods {
  }

  def mkSparkDenseMatrix[T]
    (rddVals: Rep[RDDCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkDenseMatrix[T]] =
    new ExpSparkDenseMatrix[T](rddVals, numColumns)
  def unmkSparkDenseMatrix[T](p: Rep[SparkAbstractMatrix[T]]) = p.elem.asInstanceOf[Elem[_]] match {
    case _: SparkDenseMatrixElem[T] @unchecked =>
      Some((p.asRep[SparkDenseMatrix[T]].rddVals, p.asRep[SparkDenseMatrix[T]].numColumns))
    case _ =>
      None
  }

  case class ExpSparkDenseIndexedMatrix[T]
      (override val rddVals: Rep[RDDIndexedCollection[Array[T]]], override val numColumns: Rep[Int])
      (implicit elem: Elem[T])
    extends SparkDenseIndexedMatrix[T](rddVals, numColumns) with UserTypeDef[SparkDenseIndexedMatrix[T]] {
    lazy val selfType = element[SparkDenseIndexedMatrix[T]]
    override def mirror(t: Transformer) = ExpSparkDenseIndexedMatrix[T](t(rddVals), t(numColumns))
  }

  lazy val SparkDenseIndexedMatrix: Rep[SparkDenseIndexedMatrixCompanionAbs] = new SparkDenseIndexedMatrixCompanionAbs with UserTypeDef[SparkDenseIndexedMatrixCompanionAbs] {
    lazy val selfType = element[SparkDenseIndexedMatrixCompanionAbs]
    override def mirror(t: Transformer) = this
  }

  object SparkDenseIndexedMatrixMethods {
    object numRows {
      def unapply(d: Def[_]): Option[Rep[SparkDenseIndexedMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkDenseIndexedMatrixElem[_]] && method.getName == "numRows" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkDenseIndexedMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkDenseIndexedMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object sc {
      def unapply(d: Def[_]): Option[Rep[SparkDenseIndexedMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkDenseIndexedMatrixElem[_]] && method.getName == "sc" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkDenseIndexedMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkDenseIndexedMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object rows {
      def unapply(d: Def[_]): Option[Rep[SparkDenseIndexedMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkDenseIndexedMatrixElem[_]] && method.getName == "rows" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkDenseIndexedMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkDenseIndexedMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object rmValues {
      def unapply(d: Def[_]): Option[Rep[SparkDenseIndexedMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkDenseIndexedMatrixElem[_]] && method.getName == "rmValues" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkDenseIndexedMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkDenseIndexedMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object apply_rows {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], Coll[Int]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(iRows, _*), _) if receiver.elem.isInstanceOf[SparkDenseIndexedMatrixElem[_]] && method.getName == "apply" && { val ann = method.getAnnotation(classOf[scalan.OverloadId]); ann != null && ann.value == "rows" } =>
          Some((receiver, iRows)).asInstanceOf[Option[(Rep[SparkDenseIndexedMatrix[T]], Coll[Int]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], Coll[Int]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object apply_row {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], Rep[Int]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(row, _*), _) if receiver.elem.isInstanceOf[SparkDenseIndexedMatrixElem[_]] && method.getName == "apply" && { val ann = method.getAnnotation(classOf[scalan.OverloadId]); ann != null && ann.value == "row" } =>
          Some((receiver, row)).asInstanceOf[Option[(Rep[SparkDenseIndexedMatrix[T]], Rep[Int]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], Rep[Int]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object apply {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], Rep[Int], Rep[Int]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(row, column, _*), _) if receiver.elem.isInstanceOf[SparkDenseIndexedMatrixElem[_]] && method.getName == "apply" && method.getAnnotation(classOf[scalan.OverloadId]) == null =>
          Some((receiver, row, column)).asInstanceOf[Option[(Rep[SparkDenseIndexedMatrix[T]], Rep[Int], Rep[Int]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], Rep[Int], Rep[Int]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object mapBy {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], Rep[AbstractVector[T] => AbstractVector[R]]) forSome {type T; type R}] = d match {
        case MethodCall(receiver, method, Seq(f, _*), _) if receiver.elem.isInstanceOf[SparkDenseIndexedMatrixElem[_]] && method.getName == "mapBy" =>
          Some((receiver, f)).asInstanceOf[Option[(Rep[SparkDenseIndexedMatrix[T]], Rep[AbstractVector[T] => AbstractVector[R]]) forSome {type T; type R}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], Rep[AbstractVector[T] => AbstractVector[R]]) forSome {type T; type R}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object columns {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(n, _*), _) if receiver.elem.isInstanceOf[SparkDenseIndexedMatrixElem[_]] && method.getName == "columns" =>
          Some((receiver, n)).asInstanceOf[Option[(Rep[SparkDenseIndexedMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object transpose {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(n, _*), _) if receiver.elem.isInstanceOf[SparkDenseIndexedMatrixElem[_]] && method.getName == "transpose" =>
          Some((receiver, n)).asInstanceOf[Option[(Rep[SparkDenseIndexedMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object reduceByRows {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], RepMonoid[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(m, _*), _) if receiver.elem.isInstanceOf[SparkDenseIndexedMatrixElem[_]] && method.getName == "reduceByRows" =>
          Some((receiver, m)).asInstanceOf[Option[(Rep[SparkDenseIndexedMatrix[T]], RepMonoid[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], RepMonoid[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object countNonZeroesByColumns {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(n, _*), _) if receiver.elem.isInstanceOf[SparkDenseIndexedMatrixElem[_]] && method.getName == "countNonZeroesByColumns" =>
          Some((receiver, n)).asInstanceOf[Option[(Rep[SparkDenseIndexedMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object reduceByColumns {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], RepMonoid[T], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(m, n, _*), _) if receiver.elem.isInstanceOf[SparkDenseIndexedMatrixElem[_]] && method.getName == "reduceByColumns" =>
          Some((receiver, m, n)).asInstanceOf[Option[(Rep[SparkDenseIndexedMatrix[T]], RepMonoid[T], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], RepMonoid[T], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object * {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], Vector[T], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(vector, n, _*), _) if receiver.elem.isInstanceOf[SparkDenseIndexedMatrixElem[_]] && method.getName == "$times" && method.getAnnotation(classOf[scalan.OverloadId]) == null =>
          Some((receiver, vector, n)).asInstanceOf[Option[(Rep[SparkDenseIndexedMatrix[T]], Vector[T], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], Vector[T], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object matrix_* {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], Matrix[T], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(matrix, n, _*), _) if receiver.elem.isInstanceOf[SparkDenseIndexedMatrixElem[_]] && method.getName == "$times" && { val ann = method.getAnnotation(classOf[scalan.OverloadId]); ann != null && ann.value == "matrix" } =>
          Some((receiver, matrix, n)).asInstanceOf[Option[(Rep[SparkDenseIndexedMatrix[T]], Matrix[T], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], Matrix[T], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object matrix_+^^ {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(other, n, _*), _) if receiver.elem.isInstanceOf[SparkDenseIndexedMatrixElem[_]] && method.getName == "$plus$up$up" =>
          Some((receiver, other, n)).asInstanceOf[Option[(Rep[SparkDenseIndexedMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object *^^ {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(other, n, _*), _) if receiver.elem.isInstanceOf[SparkDenseIndexedMatrixElem[_]] && method.getName == "$times$up$up" =>
          Some((receiver, other, n)).asInstanceOf[Option[(Rep[SparkDenseIndexedMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object average {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], Fractional[T], RepMonoid[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(f, m, _*), _) if receiver.elem.isInstanceOf[SparkDenseIndexedMatrixElem[_]] && method.getName == "average" =>
          Some((receiver, f, m)).asInstanceOf[Option[(Rep[SparkDenseIndexedMatrix[T]], Fractional[T], RepMonoid[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseIndexedMatrix[T]], Fractional[T], RepMonoid[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object companion {
      def unapply(d: Def[_]): Option[Rep[SparkDenseIndexedMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkDenseIndexedMatrixElem[_]] && method.getName == "companion" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkDenseIndexedMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkDenseIndexedMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }
  }

  object SparkDenseIndexedMatrixCompanionMethods {
  }

  def mkSparkDenseIndexedMatrix[T]
    (rddVals: Rep[RDDIndexedCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkDenseIndexedMatrix[T]] =
    new ExpSparkDenseIndexedMatrix[T](rddVals, numColumns)
  def unmkSparkDenseIndexedMatrix[T](p: Rep[SparkAbstractMatrix[T]]) = p.elem.asInstanceOf[Elem[_]] match {
    case _: SparkDenseIndexedMatrixElem[T] @unchecked =>
      Some((p.asRep[SparkDenseIndexedMatrix[T]].rddVals, p.asRep[SparkDenseIndexedMatrix[T]].numColumns))
    case _ =>
      None
  }

  object SparkAbstractMatrixMethods {
    object sc {
      def unapply(d: Def[_]): Option[Rep[SparkAbstractMatrix[A]] forSome {type A}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkAbstractMatrixElem[_, _]] && method.getName == "sc" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkAbstractMatrix[A]] forSome {type A}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkAbstractMatrix[A]] forSome {type A}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }
  }

  object SparkAbstractMatrixCompanionMethods {
  }
}
