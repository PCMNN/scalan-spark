package la
package impl

import scalan.OverloadId
import scalan.common.OverloadHack.{Overloaded1, Overloaded2}
import scala.reflect._
import scala.reflect.runtime.universe._
import scalan.common.Default
import scalan.spark._

// Abs -----------------------------------
trait SparkMatricesAbs extends SparkMatrices with SparkDsl {
  self: SparkLADsl =>
  // single proxy for each type family
  implicit def proxySparkAbstractMatrix[A](p: Rep[SparkAbstractMatrix[A]]): SparkAbstractMatrix[A] = {
    proxyOps[SparkAbstractMatrix[A]](p)(classTag[SparkAbstractMatrix[A]])
  }

  // familyElem
  class SparkAbstractMatrixElem[A, To <: SparkAbstractMatrix[A]](implicit override val elem: Elem[A])
    extends AbstractMatrixElem[A, To] {
    override def isEntityType = true
    override def tag = {
      implicit val tagA = elem.tag
      weakTypeTag[SparkAbstractMatrix[A]].asInstanceOf[WeakTypeTag[To]]
    }
    override def convert(x: Rep[Reifiable[_]]) = convertSparkAbstractMatrix(x.asRep[SparkAbstractMatrix[A]])
    def convertSparkAbstractMatrix(x : Rep[SparkAbstractMatrix[A]]): Rep[To] = {
      //assert(x.selfType1.isInstanceOf[SparkAbstractMatrixElem[_,_]])
      x.asRep[To]
    }
    override def getDefaultRep: Rep[To] = ???
  }

  implicit def sparkAbstractMatrixElement[A](implicit elem: Elem[A]) =
    new SparkAbstractMatrixElem[A, SparkAbstractMatrix[A]]()(elem)

  trait SparkAbstractMatrixCompanionElem extends CompanionElem[SparkAbstractMatrixCompanionAbs]
  implicit lazy val SparkAbstractMatrixCompanionElem: SparkAbstractMatrixCompanionElem = new SparkAbstractMatrixCompanionElem {
    lazy val tag = weakTypeTag[SparkAbstractMatrixCompanionAbs]
    protected def getDefaultRep = SparkAbstractMatrix
  }

  abstract class SparkAbstractMatrixCompanionAbs extends CompanionBase[SparkAbstractMatrixCompanionAbs] with SparkAbstractMatrixCompanion {
    override def toString = "SparkAbstractMatrix"
  }
  def SparkAbstractMatrix: Rep[SparkAbstractMatrixCompanionAbs]
  implicit def proxySparkAbstractMatrixCompanion(p: Rep[SparkAbstractMatrixCompanion]): SparkAbstractMatrixCompanion = {
    proxyOps[SparkAbstractMatrixCompanion](p)
  }

  // elem for concrete class
  class SparkSparseMatrixElem[T](val iso: Iso[SparkSparseMatrixData[T], SparkSparseMatrix[T]])(implicit elem: Elem[T])
    extends SparkAbstractMatrixElem[T, SparkSparseMatrix[T]]
    with ConcreteElem[SparkSparseMatrixData[T], SparkSparseMatrix[T]] {
    override def convertSparkAbstractMatrix(x: Rep[SparkAbstractMatrix[T]]) = // Converter is not generated by meta
!!!("Cannot convert from SparkAbstractMatrix to SparkSparseMatrix: missing fields List(rddIdxs, rddVals, numColumns)")
    override def getDefaultRep = super[ConcreteElem].getDefaultRep
    override lazy val tag = super[ConcreteElem].tag
  }

  // state representation type
  type SparkSparseMatrixData[T] = (RDDCollection[Array[Int]], (RDDCollection[Array[T]], Int))

  // 3) Iso for concrete class
  class SparkSparseMatrixIso[T](implicit elem: Elem[T])
    extends Iso[SparkSparseMatrixData[T], SparkSparseMatrix[T]] {
    override def from(p: Rep[SparkSparseMatrix[T]]) =
      unmkSparkSparseMatrix(p) match {
        case Some((rddIdxs, rddVals, numColumns)) => Pair(rddIdxs, Pair(rddVals, numColumns))
        case None => !!!
      }
    override def to(p: Rep[(RDDCollection[Array[Int]], (RDDCollection[Array[T]], Int))]) = {
      val Pair(rddIdxs, Pair(rddVals, numColumns)) = p
      SparkSparseMatrix(rddIdxs, rddVals, numColumns)
    }
    lazy val tag = {
      implicit val tagT = elem.tag
      weakTypeTag[SparkSparseMatrix[T]]
    }
    lazy val defaultRepTo = Default.defaultVal[Rep[SparkSparseMatrix[T]]](SparkSparseMatrix(element[RDDCollection[Array[Int]]].defaultRepValue, element[RDDCollection[Array[T]]].defaultRepValue, 0))
    lazy val eTo = new SparkSparseMatrixElem[T](this)
  }
  // 4) constructor and deconstructor
  abstract class SparkSparseMatrixCompanionAbs extends CompanionBase[SparkSparseMatrixCompanionAbs] with SparkSparseMatrixCompanion {
    override def toString = "SparkSparseMatrix"
    def apply[T](p: Rep[SparkSparseMatrixData[T]])(implicit elem: Elem[T]): Rep[SparkSparseMatrix[T]] =
      isoSparkSparseMatrix(elem).to(p)
    def apply[T](rddIdxs: Rep[RDDCollection[Array[Int]]], rddVals: Rep[RDDCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkSparseMatrix[T]] =
      mkSparkSparseMatrix(rddIdxs, rddVals, numColumns)
    def unapply[T:Elem](p: Rep[SparkSparseMatrix[T]]) = unmkSparkSparseMatrix(p)
  }
  def SparkSparseMatrix: Rep[SparkSparseMatrixCompanionAbs]
  implicit def proxySparkSparseMatrixCompanion(p: Rep[SparkSparseMatrixCompanionAbs]): SparkSparseMatrixCompanionAbs = {
    proxyOps[SparkSparseMatrixCompanionAbs](p)
  }

  class SparkSparseMatrixCompanionElem extends CompanionElem[SparkSparseMatrixCompanionAbs] {
    lazy val tag = weakTypeTag[SparkSparseMatrixCompanionAbs]
    protected def getDefaultRep = SparkSparseMatrix
  }
  implicit lazy val SparkSparseMatrixCompanionElem: SparkSparseMatrixCompanionElem = new SparkSparseMatrixCompanionElem

  implicit def proxySparkSparseMatrix[T](p: Rep[SparkSparseMatrix[T]]): SparkSparseMatrix[T] =
    proxyOps[SparkSparseMatrix[T]](p)

  implicit class ExtendedSparkSparseMatrix[T](p: Rep[SparkSparseMatrix[T]])(implicit elem: Elem[T]) {
    def toData: Rep[SparkSparseMatrixData[T]] = isoSparkSparseMatrix(elem).from(p)
  }

  // 5) implicit resolution of Iso
  implicit def isoSparkSparseMatrix[T](implicit elem: Elem[T]): Iso[SparkSparseMatrixData[T], SparkSparseMatrix[T]] =
    new SparkSparseMatrixIso[T]

  // 6) smart constructor and deconstructor
  def mkSparkSparseMatrix[T](rddIdxs: Rep[RDDCollection[Array[Int]]], rddVals: Rep[RDDCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkSparseMatrix[T]]
  def unmkSparkSparseMatrix[T:Elem](p: Rep[SparkSparseMatrix[T]]): Option[(Rep[RDDCollection[Array[Int]]], Rep[RDDCollection[Array[T]]], Rep[Int])]
}

// Seq -----------------------------------
trait SparkMatricesSeq extends SparkMatricesDsl with SparkDslSeq {
  self: SparkLADslSeq =>
  lazy val SparkAbstractMatrix: Rep[SparkAbstractMatrixCompanionAbs] = new SparkAbstractMatrixCompanionAbs with UserTypeSeq[SparkAbstractMatrixCompanionAbs] {
    lazy val selfType = element[SparkAbstractMatrixCompanionAbs]
  }

  case class SeqSparkSparseMatrix[T]
      (override val rddIdxs: Rep[RDDCollection[Array[Int]]], override val rddVals: Rep[RDDCollection[Array[T]]], override val numColumns: Rep[Int])
      (implicit elem: Elem[T])
    extends SparkSparseMatrix[T](rddIdxs, rddVals, numColumns)
        with UserTypeSeq[SparkSparseMatrix[T]] {
    lazy val selfType = element[SparkSparseMatrix[T]]
  }
  lazy val SparkSparseMatrix = new SparkSparseMatrixCompanionAbs with UserTypeSeq[SparkSparseMatrixCompanionAbs] {
    lazy val selfType = element[SparkSparseMatrixCompanionAbs]
  }

  def mkSparkSparseMatrix[T]
      (rddIdxs: Rep[RDDCollection[Array[Int]]], rddVals: Rep[RDDCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkSparseMatrix[T]] =
      new SeqSparkSparseMatrix[T](rddIdxs, rddVals, numColumns)
  def unmkSparkSparseMatrix[T:Elem](p: Rep[SparkSparseMatrix[T]]) =
    Some((p.rddIdxs, p.rddVals, p.numColumns))
}

// Exp -----------------------------------
trait SparkMatricesExp extends SparkMatricesDsl with SparkDslExp {
  self: SparkLADslExp =>
  lazy val SparkAbstractMatrix: Rep[SparkAbstractMatrixCompanionAbs] = new SparkAbstractMatrixCompanionAbs with UserTypeDef[SparkAbstractMatrixCompanionAbs] {
    lazy val selfType = element[SparkAbstractMatrixCompanionAbs]
    override def mirror(t: Transformer) = this
  }

  case class ExpSparkSparseMatrix[T]
      (override val rddIdxs: Rep[RDDCollection[Array[Int]]], override val rddVals: Rep[RDDCollection[Array[T]]], override val numColumns: Rep[Int])
      (implicit elem: Elem[T])
    extends SparkSparseMatrix[T](rddIdxs, rddVals, numColumns) with UserTypeDef[SparkSparseMatrix[T]] {
    lazy val selfType = element[SparkSparseMatrix[T]]
    override def mirror(t: Transformer) = ExpSparkSparseMatrix[T](t(rddIdxs), t(rddVals), t(numColumns))
  }

  lazy val SparkSparseMatrix: Rep[SparkSparseMatrixCompanionAbs] = new SparkSparseMatrixCompanionAbs with UserTypeDef[SparkSparseMatrixCompanionAbs] {
    lazy val selfType = element[SparkSparseMatrixCompanionAbs]
    override def mirror(t: Transformer) = this
  }

  object SparkSparseMatrixMethods {
    object numRows {
      def unapply(d: Def[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "numRows" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkSparseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object rddColl {
      def unapply(d: Def[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "rddColl" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkSparseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object rows {
      def unapply(d: Def[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "rows" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkSparseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object columns {
      def unapply(d: Def[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "columns" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkSparseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object rmValues {
      def unapply(d: Def[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "rmValues" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkSparseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object apply_rows {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Coll[Int]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(iRows, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "apply" && { val ann = method.getAnnotation(classOf[scalan.OverloadId]); ann != null && ann.value == "rows" } =>
          Some((receiver, iRows)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Coll[Int]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Coll[Int]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object apply_row {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[Int]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(row, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "apply" && { val ann = method.getAnnotation(classOf[scalan.OverloadId]); ann != null && ann.value == "row" } =>
          Some((receiver, row)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Rep[Int]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[Int]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object apply {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[Int], Rep[Int]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(row, column, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "apply"&& method.getAnnotation(classOf[scalan.OverloadId]) == null =>
          Some((receiver, row, column)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Rep[Int], Rep[Int]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[Int], Rep[Int]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object transpose {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(n, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "transpose" =>
          Some((receiver, n)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object countNonZeroesByColumns {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(n, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "countNonZeroesByColumns" =>
          Some((receiver, n)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object reduceByColumns {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], RepMonoid[T], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(m, n, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "reduceByColumns" =>
          Some((receiver, m, n)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], RepMonoid[T], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], RepMonoid[T], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object * {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Vector[T], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(vector, n, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "$times" =>
          Some((receiver, vector, n)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Vector[T], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Vector[T], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object matrix_+^^ {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(other, n, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "$plus$up$up" =>
          Some((receiver, other, n)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object *^^ {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(other, n, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "$times$up$up" =>
          Some((receiver, other, n)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object average {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Fractional[T], RepMonoid[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(f, m, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "average" =>
          Some((receiver, f, m)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Fractional[T], RepMonoid[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Fractional[T], RepMonoid[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object companion {
      def unapply(d: Def[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "companion" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkSparseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }
  }

  object SparkSparseMatrixCompanionMethods {
  }

  def mkSparkSparseMatrix[T]
    (rddIdxs: Rep[RDDCollection[Array[Int]]], rddVals: Rep[RDDCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkSparseMatrix[T]] =
    new ExpSparkSparseMatrix[T](rddIdxs, rddVals, numColumns)
  def unmkSparkSparseMatrix[T:Elem](p: Rep[SparkSparseMatrix[T]]) =
    Some((p.rddIdxs, p.rddVals, p.numColumns))

  object SparkAbstractMatrixMethods {
  }

  object SparkAbstractMatrixCompanionMethods {
  }
}
