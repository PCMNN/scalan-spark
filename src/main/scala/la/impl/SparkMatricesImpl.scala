package la
package impl

import scala.annotation.unchecked.uncheckedVariance
import scalan.OverloadId
import scalan.common.OverloadHack.{Overloaded1, Overloaded2}
import scala.reflect._
import scala.reflect.runtime.universe._
import scalan.common.Default
import scalan.spark._

// Abs -----------------------------------
trait SparkMatricesAbs extends SparkMatrices with SparkDsl {
  self: SparkLADsl =>

  // single proxy for each type family
  implicit def proxySparkAbstractMatrix[A](p: Rep[SparkAbstractMatrix[A]]): SparkAbstractMatrix[A] = {
    proxyOps[SparkAbstractMatrix[A]](p)(classTag[SparkAbstractMatrix[A]])
  }

  // familyElem
  class SparkAbstractMatrixElem[A, To <: SparkAbstractMatrix[A]](implicit override val elem: Elem[A])
    extends AbstractMatrixElem[A, To] {
    override def isEntityType = true
    override def tag = {
      implicit val tagA = elem.tag
      weakTypeTag[SparkAbstractMatrix[A]].asInstanceOf[WeakTypeTag[To]]
    }
    override def convert(x: Rep[Reifiable[_]]) = convertSparkAbstractMatrix(x.asRep[SparkAbstractMatrix[A]])
    def convertSparkAbstractMatrix(x : Rep[SparkAbstractMatrix[A]]): Rep[To] = {
      //assert(x.selfType1.isInstanceOf[SparkAbstractMatrixElem[_,_]])
      x.asRep[To]
    }
    override def getDefaultRep: Rep[To] = ???
  }

  implicit def sparkAbstractMatrixElement[A](implicit elem: Elem[A]): Elem[SparkAbstractMatrix[A]] =
    new SparkAbstractMatrixElem[A, SparkAbstractMatrix[A]] {
    }

  trait SparkAbstractMatrixCompanionElem extends CompanionElem[SparkAbstractMatrixCompanionAbs]
  implicit lazy val SparkAbstractMatrixCompanionElem: SparkAbstractMatrixCompanionElem = new SparkAbstractMatrixCompanionElem {
    lazy val tag = weakTypeTag[SparkAbstractMatrixCompanionAbs]
    protected def getDefaultRep = SparkAbstractMatrix
  }

  abstract class SparkAbstractMatrixCompanionAbs extends CompanionBase[SparkAbstractMatrixCompanionAbs] with SparkAbstractMatrixCompanion {
    override def toString = "SparkAbstractMatrix"
  }
  def SparkAbstractMatrix: Rep[SparkAbstractMatrixCompanionAbs]
  implicit def proxySparkAbstractMatrixCompanion(p: Rep[SparkAbstractMatrixCompanion]): SparkAbstractMatrixCompanion = {
    proxyOps[SparkAbstractMatrixCompanion](p)
  }

  // elem for concrete class
  class SparkSparseMatrixElem[T](val iso: Iso[SparkSparseMatrixData[T], SparkSparseMatrix[T]])(implicit elem: Elem[T])
    extends SparkAbstractMatrixElem[T, SparkSparseMatrix[T]]
    with ConcreteElem[SparkSparseMatrixData[T], SparkSparseMatrix[T]] {
    override def convertSparkAbstractMatrix(x: Rep[SparkAbstractMatrix[T]]) = // Converter is not generated by meta
!!!("Cannot convert from SparkAbstractMatrix to SparkSparseMatrix: missing fields List(rddIdxs, rddVals, numColumns)")
    override def getDefaultRep = super[ConcreteElem].getDefaultRep
    override lazy val tag = super[ConcreteElem].tag
  }

  // state representation type
  type SparkSparseMatrixData[T] = (RDDCollection[Array[Int]], (RDDCollection[Array[T]], Int))

  // 3) Iso for concrete class
  class SparkSparseMatrixIso[T](implicit elem: Elem[T])
    extends Iso[SparkSparseMatrixData[T], SparkSparseMatrix[T]]()(pairElement(implicitly[Elem[RDDCollection[Array[Int]]]], pairElement(implicitly[Elem[RDDCollection[Array[T]]]], implicitly[Elem[Int]]))) {
    override def from(p: Rep[SparkSparseMatrix[T]]) =
      (p.rddIdxs, p.rddVals, p.numColumns)
    override def to(p: Rep[(RDDCollection[Array[Int]], (RDDCollection[Array[T]], Int))]) = {
      val Pair(rddIdxs, Pair(rddVals, numColumns)) = p
      SparkSparseMatrix(rddIdxs, rddVals, numColumns)
    }
    lazy val tag = {
      implicit val tagT = elem.tag
      weakTypeTag[SparkSparseMatrix[T]]
    }
    lazy val defaultRepTo = Default.defaultVal[Rep[SparkSparseMatrix[T]]](SparkSparseMatrix(element[RDDCollection[Array[Int]]].defaultRepValue, element[RDDCollection[Array[T]]].defaultRepValue, 0))
    lazy val eTo = new SparkSparseMatrixElem[T](this)
  }
  // 4) constructor and deconstructor
  abstract class SparkSparseMatrixCompanionAbs extends CompanionBase[SparkSparseMatrixCompanionAbs] with SparkSparseMatrixCompanion {
    override def toString = "SparkSparseMatrix"
    def apply[T](p: Rep[SparkSparseMatrixData[T]])(implicit elem: Elem[T]): Rep[SparkSparseMatrix[T]] =
      isoSparkSparseMatrix(elem).to(p)
    def apply[T](rddIdxs: Rep[RDDCollection[Array[Int]]], rddVals: Rep[RDDCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkSparseMatrix[T]] =
      mkSparkSparseMatrix(rddIdxs, rddVals, numColumns)
  }
  object SparkSparseMatrixMatcher {
    def unapply[T](p: Rep[SparkAbstractMatrix[T]]) = unmkSparkSparseMatrix(p)
  }
  def SparkSparseMatrix: Rep[SparkSparseMatrixCompanionAbs]
  implicit def proxySparkSparseMatrixCompanion(p: Rep[SparkSparseMatrixCompanionAbs]): SparkSparseMatrixCompanionAbs = {
    proxyOps[SparkSparseMatrixCompanionAbs](p)
  }

  class SparkSparseMatrixCompanionElem extends CompanionElem[SparkSparseMatrixCompanionAbs] {
    lazy val tag = weakTypeTag[SparkSparseMatrixCompanionAbs]
    protected def getDefaultRep = SparkSparseMatrix
  }
  implicit lazy val SparkSparseMatrixCompanionElem: SparkSparseMatrixCompanionElem = new SparkSparseMatrixCompanionElem

  implicit def proxySparkSparseMatrix[T](p: Rep[SparkSparseMatrix[T]]): SparkSparseMatrix[T] =
    proxyOps[SparkSparseMatrix[T]](p)

  implicit class ExtendedSparkSparseMatrix[T](p: Rep[SparkSparseMatrix[T]])(implicit elem: Elem[T]) {
    def toData: Rep[SparkSparseMatrixData[T]] = isoSparkSparseMatrix(elem).from(p)
  }

  // 5) implicit resolution of Iso
  implicit def isoSparkSparseMatrix[T](implicit elem: Elem[T]): Iso[SparkSparseMatrixData[T], SparkSparseMatrix[T]] =
    new SparkSparseMatrixIso[T]

  // 6) smart constructor and deconstructor
  def mkSparkSparseMatrix[T](rddIdxs: Rep[RDDCollection[Array[Int]]], rddVals: Rep[RDDCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkSparseMatrix[T]]
  def unmkSparkSparseMatrix[T](p: Rep[SparkAbstractMatrix[T]]): Option[(Rep[RDDCollection[Array[Int]]], Rep[RDDCollection[Array[T]]], Rep[Int])]

  // elem for concrete class
  class SparkDenseMatrixElem[T](val iso: Iso[SparkDenseMatrixData[T], SparkDenseMatrix[T]])(implicit elem: Elem[T])
    extends SparkAbstractMatrixElem[T, SparkDenseMatrix[T]]
    with ConcreteElem[SparkDenseMatrixData[T], SparkDenseMatrix[T]] {
    override def convertSparkAbstractMatrix(x: Rep[SparkAbstractMatrix[T]]) = // Converter is not generated by meta
!!!("Cannot convert from SparkAbstractMatrix to SparkDenseMatrix: missing fields List(rddVals, numColumns)")
    override def getDefaultRep = super[ConcreteElem].getDefaultRep
    override lazy val tag = super[ConcreteElem].tag
  }

  // state representation type
  type SparkDenseMatrixData[T] = (RDDCollection[Array[T]], Int)

  // 3) Iso for concrete class
  class SparkDenseMatrixIso[T](implicit elem: Elem[T])
    extends Iso[SparkDenseMatrixData[T], SparkDenseMatrix[T]] {
    override def from(p: Rep[SparkDenseMatrix[T]]) =
      (p.rddVals, p.numColumns)
    override def to(p: Rep[(RDDCollection[Array[T]], Int)]) = {
      val Pair(rddVals, numColumns) = p
      SparkDenseMatrix(rddVals, numColumns)
    }
    lazy val tag = {
      implicit val tagT = elem.tag
      weakTypeTag[SparkDenseMatrix[T]]
    }
    lazy val defaultRepTo = Default.defaultVal[Rep[SparkDenseMatrix[T]]](SparkDenseMatrix(element[RDDCollection[Array[T]]].defaultRepValue, 0))
    lazy val eTo = new SparkDenseMatrixElem[T](this)
  }
  // 4) constructor and deconstructor
  abstract class SparkDenseMatrixCompanionAbs extends CompanionBase[SparkDenseMatrixCompanionAbs] with SparkDenseMatrixCompanion {
    override def toString = "SparkDenseMatrix"
    def apply[T](p: Rep[SparkDenseMatrixData[T]])(implicit elem: Elem[T]): Rep[SparkDenseMatrix[T]] =
      isoSparkDenseMatrix(elem).to(p)
    def apply[T](rddVals: Rep[RDDCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkDenseMatrix[T]] =
      mkSparkDenseMatrix(rddVals, numColumns)
  }
  object SparkDenseMatrixMatcher {
    def unapply[T](p: Rep[SparkAbstractMatrix[T]]) = unmkSparkDenseMatrix(p)
  }
  def SparkDenseMatrix: Rep[SparkDenseMatrixCompanionAbs]
  implicit def proxySparkDenseMatrixCompanion(p: Rep[SparkDenseMatrixCompanionAbs]): SparkDenseMatrixCompanionAbs = {
    proxyOps[SparkDenseMatrixCompanionAbs](p)
  }

  class SparkDenseMatrixCompanionElem extends CompanionElem[SparkDenseMatrixCompanionAbs] {
    lazy val tag = weakTypeTag[SparkDenseMatrixCompanionAbs]
    protected def getDefaultRep = SparkDenseMatrix
  }
  implicit lazy val SparkDenseMatrixCompanionElem: SparkDenseMatrixCompanionElem = new SparkDenseMatrixCompanionElem

  implicit def proxySparkDenseMatrix[T](p: Rep[SparkDenseMatrix[T]]): SparkDenseMatrix[T] =
    proxyOps[SparkDenseMatrix[T]](p)

  implicit class ExtendedSparkDenseMatrix[T](p: Rep[SparkDenseMatrix[T]])(implicit elem: Elem[T]) {
    def toData: Rep[SparkDenseMatrixData[T]] = isoSparkDenseMatrix(elem).from(p)
  }

  // 5) implicit resolution of Iso
  implicit def isoSparkDenseMatrix[T](implicit elem: Elem[T]): Iso[SparkDenseMatrixData[T], SparkDenseMatrix[T]] =
    new SparkDenseMatrixIso[T]

  // 6) smart constructor and deconstructor
  def mkSparkDenseMatrix[T](rddVals: Rep[RDDCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkDenseMatrix[T]]
  def unmkSparkDenseMatrix[T](p: Rep[SparkAbstractMatrix[T]]): Option[(Rep[RDDCollection[Array[T]]], Rep[Int])]
}

// Seq -----------------------------------
trait SparkMatricesSeq extends SparkMatricesDsl with SparkDslSeq {
  self: SparkLADslSeq =>
  lazy val SparkAbstractMatrix: Rep[SparkAbstractMatrixCompanionAbs] = new SparkAbstractMatrixCompanionAbs with UserTypeSeq[SparkAbstractMatrixCompanionAbs] {
    lazy val selfType = element[SparkAbstractMatrixCompanionAbs]
  }

  case class SeqSparkSparseMatrix[T]
      (override val rddIdxs: Rep[RDDCollection[Array[Int]]], override val rddVals: Rep[RDDCollection[Array[T]]], override val numColumns: Rep[Int])
      (implicit elem: Elem[T])
    extends SparkSparseMatrix[T](rddIdxs, rddVals, numColumns)
        with UserTypeSeq[SparkSparseMatrix[T]] {
    lazy val selfType = element[SparkSparseMatrix[T]]
  }
  lazy val SparkSparseMatrix = new SparkSparseMatrixCompanionAbs with UserTypeSeq[SparkSparseMatrixCompanionAbs] {
    lazy val selfType = element[SparkSparseMatrixCompanionAbs]
  }

  def mkSparkSparseMatrix[T]
      (rddIdxs: Rep[RDDCollection[Array[Int]]], rddVals: Rep[RDDCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkSparseMatrix[T]] =
      new SeqSparkSparseMatrix[T](rddIdxs, rddVals, numColumns)
  def unmkSparkSparseMatrix[T](p: Rep[SparkAbstractMatrix[T]]) = p match {
    case p: SparkSparseMatrix[T] @unchecked =>
      Some((p.rddIdxs, p.rddVals, p.numColumns))
    case _ => None
  }

  case class SeqSparkDenseMatrix[T]
      (override val rddVals: Rep[RDDCollection[Array[T]]], override val numColumns: Rep[Int])
      (implicit elem: Elem[T])
    extends SparkDenseMatrix[T](rddVals, numColumns)
        with UserTypeSeq[SparkDenseMatrix[T]] {
    lazy val selfType = element[SparkDenseMatrix[T]]
  }
  lazy val SparkDenseMatrix = new SparkDenseMatrixCompanionAbs with UserTypeSeq[SparkDenseMatrixCompanionAbs] {
    lazy val selfType = element[SparkDenseMatrixCompanionAbs]
  }

  def mkSparkDenseMatrix[T]
      (rddVals: Rep[RDDCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkDenseMatrix[T]] =
      new SeqSparkDenseMatrix[T](rddVals, numColumns)
  def unmkSparkDenseMatrix[T](p: Rep[SparkAbstractMatrix[T]]) = p match {
    case p: SparkDenseMatrix[T] @unchecked =>
      Some((p.rddVals, p.numColumns))
    case _ => None
  }
}

// Exp -----------------------------------
trait SparkMatricesExp extends SparkMatricesDsl with SparkDslExp {
  self: SparkLADslExp =>
  lazy val SparkAbstractMatrix: Rep[SparkAbstractMatrixCompanionAbs] = new SparkAbstractMatrixCompanionAbs with UserTypeDef[SparkAbstractMatrixCompanionAbs] {
    lazy val selfType = element[SparkAbstractMatrixCompanionAbs]
    override def mirror(t: Transformer) = this
  }

  case class ExpSparkSparseMatrix[T]
      (override val rddIdxs: Rep[RDDCollection[Array[Int]]], override val rddVals: Rep[RDDCollection[Array[T]]], override val numColumns: Rep[Int])
      (implicit elem: Elem[T])
    extends SparkSparseMatrix[T](rddIdxs, rddVals, numColumns) with UserTypeDef[SparkSparseMatrix[T]] {
    lazy val selfType = element[SparkSparseMatrix[T]]
    override def mirror(t: Transformer) = ExpSparkSparseMatrix[T](t(rddIdxs), t(rddVals), t(numColumns))
  }

  lazy val SparkSparseMatrix: Rep[SparkSparseMatrixCompanionAbs] = new SparkSparseMatrixCompanionAbs with UserTypeDef[SparkSparseMatrixCompanionAbs] {
    lazy val selfType = element[SparkSparseMatrixCompanionAbs]
    override def mirror(t: Transformer) = this
  }

  object SparkSparseMatrixMethods {
    object numRows {
      def unapply(d: Def[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "numRows" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkSparseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object rddColl {
      def unapply(d: Def[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "rddColl" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkSparseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object sc {
      def unapply(d: Def[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "sc" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkSparseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object rows {
      def unapply(d: Def[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "rows" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkSparseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object rmValues {
      def unapply(d: Def[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "rmValues" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkSparseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object apply_rows {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Coll[Int]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(iRows, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "apply" && { val ann = method.getAnnotation(classOf[scalan.OverloadId]); ann != null && ann.value == "rows" } =>
          Some((receiver, iRows)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Coll[Int]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Coll[Int]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object apply_row {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[Int]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(row, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "apply" && { val ann = method.getAnnotation(classOf[scalan.OverloadId]); ann != null && ann.value == "row" } =>
          Some((receiver, row)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Rep[Int]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[Int]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object apply {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[Int], Rep[Int]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(row, column, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "apply" && method.getAnnotation(classOf[scalan.OverloadId]) == null =>
          Some((receiver, row, column)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Rep[Int], Rep[Int]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[Int], Rep[Int]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object mapBy {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[AbstractVector[T] => AbstractVector[R]]) forSome {type T; type R}] = d match {
        case MethodCall(receiver, method, Seq(f, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "mapBy" =>
          Some((receiver, f)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Rep[AbstractVector[T] => AbstractVector[R]]) forSome {type T; type R}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[AbstractVector[T] => AbstractVector[R]]) forSome {type T; type R}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object columns {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(n, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "columns" =>
          Some((receiver, n)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object transpose {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(n, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "transpose" =>
          Some((receiver, n)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object reduceByRows {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], RepMonoid[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(m, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "reduceByRows" =>
          Some((receiver, m)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], RepMonoid[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], RepMonoid[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object countNonZeroesByColumns {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(n, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "countNonZeroesByColumns" =>
          Some((receiver, n)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object reduceByColumns {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], RepMonoid[T], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(m, n, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "reduceByColumns" =>
          Some((receiver, m, n)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], RepMonoid[T], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], RepMonoid[T], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object * {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Vector[T], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(vector, n, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "$times" && method.getAnnotation(classOf[scalan.OverloadId]) == null =>
          Some((receiver, vector, n)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Vector[T], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Vector[T], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object matrix_* {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Matrix[T], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(matrix, n, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "$times" && { val ann = method.getAnnotation(classOf[scalan.OverloadId]); ann != null && ann.value == "matrix" } =>
          Some((receiver, matrix, n)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Matrix[T], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Matrix[T], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object matrix_+^^ {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(other, n, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "$plus$up$up" =>
          Some((receiver, other, n)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object *^^ {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(other, n, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "$times$up$up" =>
          Some((receiver, other, n)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object average {
      def unapply(d: Def[_]): Option[(Rep[SparkSparseMatrix[T]], Fractional[T], RepMonoid[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(f, m, _*), _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "average" =>
          Some((receiver, f, m)).asInstanceOf[Option[(Rep[SparkSparseMatrix[T]], Fractional[T], RepMonoid[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkSparseMatrix[T]], Fractional[T], RepMonoid[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object companion {
      def unapply(d: Def[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkSparseMatrixElem[_]] && method.getName == "companion" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkSparseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkSparseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }
  }

  object SparkSparseMatrixCompanionMethods {
  }

  def mkSparkSparseMatrix[T]
    (rddIdxs: Rep[RDDCollection[Array[Int]]], rddVals: Rep[RDDCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkSparseMatrix[T]] =
    new ExpSparkSparseMatrix[T](rddIdxs, rddVals, numColumns)
  def unmkSparkSparseMatrix[T](p: Rep[SparkAbstractMatrix[T]]) = p.elem.asInstanceOf[Elem[_]] match {
    case _: SparkSparseMatrixElem[T] @unchecked =>
      Some((p.asRep[SparkSparseMatrix[T]].rddIdxs, p.asRep[SparkSparseMatrix[T]].rddVals, p.asRep[SparkSparseMatrix[T]].numColumns))
    case _ =>
      None
  }

  case class ExpSparkDenseMatrix[T]
      (override val rddVals: Rep[RDDCollection[Array[T]]], override val numColumns: Rep[Int])
      (implicit elem: Elem[T])
    extends SparkDenseMatrix[T](rddVals, numColumns) with UserTypeDef[SparkDenseMatrix[T]] {
    lazy val selfType = element[SparkDenseMatrix[T]]
    override def mirror(t: Transformer) = ExpSparkDenseMatrix[T](t(rddVals), t(numColumns))
  }

  lazy val SparkDenseMatrix: Rep[SparkDenseMatrixCompanionAbs] = new SparkDenseMatrixCompanionAbs with UserTypeDef[SparkDenseMatrixCompanionAbs] {
    lazy val selfType = element[SparkDenseMatrixCompanionAbs]
    override def mirror(t: Transformer) = this
  }

  object SparkDenseMatrixMethods {
    object numRows {
      def unapply(d: Def[_]): Option[Rep[SparkDenseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "numRows" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkDenseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkDenseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object sc {
      def unapply(d: Def[_]): Option[Rep[SparkDenseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "sc" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkDenseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkDenseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object rows {
      def unapply(d: Def[_]): Option[Rep[SparkDenseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "rows" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkDenseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkDenseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object rmValues {
      def unapply(d: Def[_]): Option[Rep[SparkDenseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "rmValues" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkDenseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkDenseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object apply_rows {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], Coll[Int]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(iRows, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "apply" && { val ann = method.getAnnotation(classOf[scalan.OverloadId]); ann != null && ann.value == "rows" } =>
          Some((receiver, iRows)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], Coll[Int]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], Coll[Int]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object apply_row {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], Rep[Int]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(row, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "apply" && { val ann = method.getAnnotation(classOf[scalan.OverloadId]); ann != null && ann.value == "row" } =>
          Some((receiver, row)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], Rep[Int]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], Rep[Int]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object apply {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], Rep[Int], Rep[Int]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(row, column, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "apply" && method.getAnnotation(classOf[scalan.OverloadId]) == null =>
          Some((receiver, row, column)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], Rep[Int], Rep[Int]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], Rep[Int], Rep[Int]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object mapBy {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], Rep[AbstractVector[T] => AbstractVector[R]]) forSome {type T; type R}] = d match {
        case MethodCall(receiver, method, Seq(f, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "mapBy" =>
          Some((receiver, f)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], Rep[AbstractVector[T] => AbstractVector[R]]) forSome {type T; type R}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], Rep[AbstractVector[T] => AbstractVector[R]]) forSome {type T; type R}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object columns {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(n, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "columns" =>
          Some((receiver, n)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object transpose {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(n, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "transpose" =>
          Some((receiver, n)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object reduceByRows {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], RepMonoid[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(m, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "reduceByRows" =>
          Some((receiver, m)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], RepMonoid[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], RepMonoid[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object countNonZeroesByColumns {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(n, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "countNonZeroesByColumns" =>
          Some((receiver, n)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object reduceByColumns {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], RepMonoid[T], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(m, n, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "reduceByColumns" =>
          Some((receiver, m, n)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], RepMonoid[T], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], RepMonoid[T], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object * {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], Vector[T], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(vector, n, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "$times" && method.getAnnotation(classOf[scalan.OverloadId]) == null =>
          Some((receiver, vector, n)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], Vector[T], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], Vector[T], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object matrix_* {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], Matrix[T], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(matrix, n, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "$times" && { val ann = method.getAnnotation(classOf[scalan.OverloadId]); ann != null && ann.value == "matrix" } =>
          Some((receiver, matrix, n)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], Matrix[T], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], Matrix[T], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object matrix_+^^ {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(other, n, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "$plus$up$up" =>
          Some((receiver, other, n)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object *^^ {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(other, n, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "$times$up$up" =>
          Some((receiver, other, n)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], Rep[AbstractMatrix[T]], Numeric[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object average {
      def unapply(d: Def[_]): Option[(Rep[SparkDenseMatrix[T]], Fractional[T], RepMonoid[T]) forSome {type T}] = d match {
        case MethodCall(receiver, method, Seq(f, m, _*), _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "average" =>
          Some((receiver, f, m)).asInstanceOf[Option[(Rep[SparkDenseMatrix[T]], Fractional[T], RepMonoid[T]) forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[(Rep[SparkDenseMatrix[T]], Fractional[T], RepMonoid[T]) forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }

    object companion {
      def unapply(d: Def[_]): Option[Rep[SparkDenseMatrix[T]] forSome {type T}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkDenseMatrixElem[_]] && method.getName == "companion" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkDenseMatrix[T]] forSome {type T}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkDenseMatrix[T]] forSome {type T}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }
  }

  object SparkDenseMatrixCompanionMethods {
  }

  def mkSparkDenseMatrix[T]
    (rddVals: Rep[RDDCollection[Array[T]]], numColumns: Rep[Int])(implicit elem: Elem[T]): Rep[SparkDenseMatrix[T]] =
    new ExpSparkDenseMatrix[T](rddVals, numColumns)
  def unmkSparkDenseMatrix[T](p: Rep[SparkAbstractMatrix[T]]) = p.elem.asInstanceOf[Elem[_]] match {
    case _: SparkDenseMatrixElem[T] @unchecked =>
      Some((p.asRep[SparkDenseMatrix[T]].rddVals, p.asRep[SparkDenseMatrix[T]].numColumns))
    case _ =>
      None
  }

  object SparkAbstractMatrixMethods {
    object sc {
      def unapply(d: Def[_]): Option[Rep[SparkAbstractMatrix[A]] forSome {type A}] = d match {
        case MethodCall(receiver, method, _, _) if receiver.elem.isInstanceOf[SparkAbstractMatrixElem[_, _]] && method.getName == "sc" =>
          Some(receiver).asInstanceOf[Option[Rep[SparkAbstractMatrix[A]] forSome {type A}]]
        case _ => None
      }
      def unapply(exp: Exp[_]): Option[Rep[SparkAbstractMatrix[A]] forSome {type A}] = exp match {
        case Def(d) => unapply(d)
        case _ => None
      }
    }
  }

  object SparkAbstractMatrixCompanionMethods {
  }
}
